---
title: "A2_code"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# packages
library(pacman)
p_load(tidyverse, ggunchained, rstan, rethinking)


# STAN SETUP
rstan_options(auto_write = TRUE)
```


# QUESTION 1

```{r}
ric <- data.frame(ID = rep("Riccardo", 6),
                      answer = c(0, 0, 0, 1, 1, 1))

kri <- data.frame(ID = rep("Kristian", 2),
                  answer = c(1, 1))

jos <- data.frame(ID = rep("Josh", 198),
                  answer = c(rep(1, 160), rep(0, 38)))

mik <- data.frame(ID = rep("Mikkel", 132),
                  answer = c(rep(1, 66), rep(0, 66)))

q1_data <- full_join(ric, kri) %>%
  full_join(jos) %>%
  full_join(mik)

# Create and join data.frames (Do we need to join here? Could we not just make a joint data.frame from the start? :)

rm("jos", "mik","kri","ric") # Cleans the environment
```

```{r grid approximation}
p_grid = seq(from = 0, to = 1, length.out = 10000) #Generates a sequence of 1000 points between 0 and 1. This is the probability distribution generated by our grid approximation.

uniprior = rep( 1 , 10000) # Makes each outcome on our probability distribution equally likely ( Uniform prior)

likelihood = dbinom(3, size = 6, prob = p_grid) # The actual likelihood of Riccardo

unstd.posterior = likelihood * uniprior

RF_posterior = unstd.posterior / sum(unstd.posterior)

plot( p_grid, RF_posterior, type = "b" # type "b" specifies that we want lines between our points (difficult to see here because of the number of points)
      , xlab = "probability that Riccardo á¸±nows more than chance", ylab = "posterior probability")


samples = sample(p_grid, prob = RF_posterior, size = 1e4, replace = T)

plot(samples)

dens(samples)

sum(samples > 0.5) / 1e4
```
dunif(0,1)

```{r RF quadratic approximation}
RF.qa = rethinking::map(
  alist(
    w ~ dbinom(6,p) ,
    p ~ dunif(0,1)
  ) ,
  data = list(w=3))

precis(RF.qa)

post = extract.samples(RF.qa, n = 1e4)
head(post)
```


# QUESTION 2
```{r}

#Function for generating posterior distributions
#posterior_gen takes 3 arguments:
#* cog = teacher for which the posterior generation is #generated
#* grid = the grid approximation used i.e. grid = seq(from #= 0, to = 1, length. out = 100) (useful for specifying #different        amount of generated points)
#* prior = prior i.e. the uniform prior

#It then generates a binomial likelihood by summing all #the correct answers of one teacher and weighing it #against the total number of answers given by that teacher.
#Finally it plots the posterior distribution.

posterior_gen = function(cog, grid, prior, sample_size = 1e4, give_sample = F, sum_posterior = T, dens_sample = T, data) {
  likelihood = dbinom(x = sum(data$ID == cog & data$answer == 1), size = sum(data$ID == cog), prob = grid)
  prior = prior
  unstd.post = likelihood * prior
  post = unstd.post / sum(unstd.post) # Normalizing
  samples = sample(grid, prob = post, size = sample_size , replace = T)
  if (cog == "Mikkel") {
    plot(grid, post, type = "b",
       xlab = "Mikkel probably doesn't know more than chance", ylab = "posterior probability") # self-explanatory
  } else {
    plot(grid, post, type = "b",
       xlab = str_c("Probability that ", cog," knows more than chance level"), ylab = "posterior probability") }
  if (give_sample == T) {
    plot(samples, xlab = str_c(sample_size, " sized sample from ", cog, "'s posterior distribution")) }
  if (dens_sample == T) {
    dens(samples, xlab = str_c("density plot of ", sample_size, " samples from ", cog, "'s posterior distribution"), show.HPDI = .95)
  }
  if (sum_posterior == T) {
    str_c(" The posterior probability that ", cog, " knows more than chance is ", sum(samples > 0.5) / sample_size)
  }
}

#sum(samples > 0.5) / sample_size)

cogs = c("Riccardo", "Mikkel", "Josh", "Kristian")

lapply(cogs, posterior_gen, grid = p_grid, prior = uniprior, data = q1_data) #generating posterior distributions for all teachers using a uniform prior

plot(uniprior, xlab = "Uniform Prior", ylab = "Probability") # Plots a uniform prior, this is the same for all teachers

```


# QUESTION 3
```{r}

#p_grid <- seq(0,1, length=10000) # This is just here for convenience, no values are changed from its previous iteration

app_prior <- dnorm(p_grid, mean=0.8, sd=0.2) # More appreciative (naive?) prior

#plot(app_prior) # Plots the appreciative prior


#lapply(cogs, posterior_gen, grid = p_grid, prior = uniprior) # Applies the uniform prior, uncomment for comparative purposes

lapply(cogs, posterior_gen, grid = p_grid, prior = app_prior, data = q1_data) # Generates posterior distributions for all teachers using appreciative prior
```


# QUESTION 4
```{r}
#p_grid <- seq(0,1, length=1000)

#app_prior <- dnorm(p_grid, mean=0.8, sd=0.2)

#lapply(cogs, posterior_gen, grid = p_grid, prior = uniprior)

#lapply(cogs, posterior_gen, grid = p_grid, prior = app_prior)

ric <- data.frame(ID = rep("Riccardo", 6*100),
                      answer = c(rep(0, 3*100), rep(1, 3*100)))

kri <- data.frame(ID = rep("Kristian", 2*100),
                  answer = c(rep(1,1*100), rep(0,0)))

jos <- data.frame(ID = rep("Josh", 198*100),
                  answer = c(rep(1, 160*100), rep(0, 38*100)))

mik <- data.frame(ID = rep("Mikkel", 132*100),
                  answer = c(rep(1, 66*100), rep(0, 66*100)))

q4_data <- full_join(ric, kri) %>%
  full_join(jos) %>%
  full_join(mik)

rm(ric,mik,jos,kri)


#big_grid = seq(0, 1, length.out = 100000) # Grid with 100 times the points - Bigger, Better, Stronger!


app_prior = dnorm(p_grid, mean = 0.8, sd=0.2)

lapply(cogs, posterior_gen, grid = p_grid, prior = uniprior, give_sample = F, data = q4_data)


```

```{r}
lapply(cogs, posterior_gen, grid = p_grid, prior = app_prior, give_sample = F, data = q4_data)
```



# QUESTION 5
```{r}
hashtagskeptic = dnorm(p_grid, mean = 0.3, sd = 0.01)

lapply(cogs, posterior_gen, grid = p_grid, prior = hashtagskeptic, give_sample = F, data = q1_data) #Which data set are we using here?

```


# QUESTION 6 - BONUS
```{r}

```

# QUESTION 7
```{r}
library(brms)
d <- data.frame(
  Correct=c(3,2,160,66),
  Questions=c(6,2,198,132),
  Teacher=c("RF","KT","JS","MW"))

FlatModel <- brm(Correct|trials(Questions)~1,data=subset(d,Teacher=="RF"),prior=prior("uniform(0,1)", class = "Intercept"),family=binomial)

plot(FlatModel)

PositiveModel <- brm(Correct|trials(Questions)~1,data=subset(d,Teacher=="RF"),prior=prior("normal(0.8,0.2)", class = "Intercept"),family=binomial)

plot(PositiveModel)

SkepticalModel <- brm(Correct|trials(Questions)~1,data=subset(d,Teacher=="RF"),prior=prior("normal(0.5,0.01)", class = "Intercept"),family=binomial)

plot(SkepticalModel)

# Tweaking the models
```

